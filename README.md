# Machine-learning-PCA
El Análisis de Componentes Principales (PCA, por sus siglas en inglés) es una técnica de reducción de dimensionalidad que se utiliza en Machine Learning para simplificar conjuntos de datos complejos mientras se conserva la mayor parte de la variabilidad presente en los datos. PCA transforma los datos originales en un nuevo conjunto de variables, llamadas componentes principales, que son ortogonales entre sí y ordenadas por la cantidad de variabilidad que capturan.

Conceptos Clave en PCA
Dimensionalidad: Se refiere al número de características (o variables) en un conjunto de datos. A menudo, los datos en alta dimensionalidad pueden ser difíciles de interpretar y pueden causar problemas como el sobreajuste.

Componentes Principales: Son las nuevas variables generadas por PCA. Cada componente principal es una combinación lineal de las variables originales, y las primeras componentes capturan la mayor parte de la variabilidad en los datos.

Varianza: PCA busca maximizar la varianza en los datos al proyectarlos en un espacio de menor dimensión. Cuanto más alta sea la varianza de un componente, más información retiene del conjunto de datos original.

Autovalores y Autovectores: Los autovalores indican la cantidad de varianza capturada por cada componente principal, y los autovectores determinan la dirección de estos componentes en el espacio de características original.
